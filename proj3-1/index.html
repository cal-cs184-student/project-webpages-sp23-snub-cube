<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
<style>
  body {
    background-color: white;
    padding: 100px;
    width: 1000px;
    margin: auto;
    text-align: left;
    font-weight: 300;
    font-family: 'Open Sans', sans-serif;
    color: #121212;
  }
  h1, h2, h3, h4 {
    font-family: 'Source Sans Pro', sans-serif;
  }
  kbd {
    color: #121212;
  }
</style>
<title>CS 184 Path Tracer</title>
<meta http-equiv="content-type" content="text/html; charset=utf-8" />
<link href="https://fonts.googleapis.com/css?family=Open+Sans|Source+Sans+Pro" rel="stylesheet">

<script>
  MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']]
    }
  };
</script>
<script id="MathJax-script" async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js">
</script>

</head>


<body>

<h1 align="middle">CS 184: Computer Graphics and Imaging, Spring 2023</h1>
<h1 align="middle">Project 3-1: Path Tracer</h1>
<h2 align="middle">Morgan Lyu</h2>

<!-- Add Website URL -->
<h2 align="middle">Website URL: <a href="TODO">TODO</a></h2>

<br><br>


<div>

<h2 align="middle">Overview</h2>
<p>
    In this project, methods to render scenes are implemented. I learned how to ray-trace by generating rays and testing its intersections. Realistic scene 
    lighting options such as direct and global are achieved through use of techniques like uniform hemisphere sampling, light sampling, as well as Russian
    roulette. Adaptive sampling and BVH are used to reduce rendering times.
</p>
<br>

<h2 align="middle">Part 1: Ray Generation and Scene Intersection (20 Points)</h2>
<!-- Walk through the ray generation and primitive intersection parts of the rendering pipeline.
Explain the triangle intersection algorithm you implemented in your own words.
Show images with normal shading for a few small .dae files. -->

<h3>
  Walk through the ray generation and primitive intersection parts of the rendering pipeline.
</h3>
<p>
    A ray has an origin, direction, and t: a valid range. The origin is its camera position, direction is going from the origin to a pixel on the sensor.
    To locate the pixel corredinates, image corredinate is transformed to camera space. The ray is generated in 
    camera space and transformed into the world space. t is arbitrarily defaulted to nclip and fclip.
    Multiple rays are generated given any pixel so that they return many samples at primitive intersections.
</p>
<br>

<h3>
  Explain the triangle intersection algorithm you implemented in your own words.
</h3>
<p>
    I used the Moller Trumbore algorithm in detecting intersections between ray and triangle.
</p>
<img src="images/eq1.png" align="middle" width="400px"/>
<p>
  where p1 p2 p3 are coordinates of the triangle, and (1-b1-b2), b1, b2 are barycentric coordinates. t, b1, b2 are calculated.
  By checking whether or not t is within the range of the ray's min and max t given the scene, and that all the barycentric coordinates are within the range of 0 and 1,
  we can determine if there is an intersection.
  Once an intersection is determined, max_t and intersection (t, n, primitive, bsdf) are updated. Intersection further than max_t are ignored.
</p>
<p>

</p>
<br>

<h3>
  Here are images with normal shading for a few small .dae files.
</h3>
<!-- Example of including multiple figures -->
<div align="middle">
  <table style="width:100%">
    <tr align="center">
      <td>
        <img src="images/P1.png" align="middle" width="400px"/>
        <figcaption>banana.dae</figcaption>
      </td>
      <td>
        <img src="images/P2.png" align="middle" width="400px"/>
        <figcaption>CBspheres_lambertian.dae</figcaption>
      </td>
    </tr>
    <tr align="center">
      <td>
        <img src="images/P3.png" align="middle" width="400px"/>
        <figcaption>CBgems.dae</figcaption>
      </td>
      <td>
        <img src="images/P4.png" align="middle" width="400px"/>
        <figcaption>CBlucy.dae</figcaption>
      </td>
    </tr>
  </table>
</div>
<br>


<h2 align="middle">Part 2: Bounding Volume Hierarchy (20 Points)</h2>
<!-- Walk through your BVH construction algorithm. Explain the heuristic you chose for picking the splitting point.
Show images with normal shading for a few large .dae files that you can only render with BVH acceleration.
Compare rendering times on a few scenes with moderately complex geometries with and without BVH acceleration. Present your results in a one-paragraph analysis. -->

<h3>
  Walk through your BVH construction algorithm. Explain the heuristic you chose for picking the splitting point.
</h3>
<p>
    BVH is implemented with recursion. 
    First, all primitives are to be considered and the average of their centroids are found.
    They are to be divided into 2 smaller groups across either x, y, or z dimensions at the point of the average centroid.
    Which dimension they are to be split exactly is determined by Surface Area Heuristic so as to achieve lower cost.
    This is recursed until the number of primitives within each group is smaller than the max leaf size.
    If all primitives share the same centroid, then the recursion is broken arbitrarily.
</p>

<h3>
  Show images with normal shading for a few large .dae files that you can only render with BVH acceleration.
</h3>
<!-- Example of including multiple figures -->
<div align="middle">
  <table style="width:100%">
    <tr align="center">
      <td>
        <img src="images/2-1.png" align="middle" width="400px"/>
        <figcaption>cow.dae, 5856 primitives</figcaption>
      </td>
      <td>
        <img src="images/2-2.png" align="middle" width="400px"/>
        <figcaption>maxplanck.dae, 50801 primitives</figcaption>
      </td>
    </tr>
    <tr align="center">
      <td>
        <img src="images/2-3.png" align="middle" width="400px"/>
        <figcaption>CBlucy.dae, 133796 primitives</figcaption>
      </td>
      <td>
        <img src="images/2-4.png" align="middle" width="400px"/>
        <figcaption>bunny.dae, 33696 primitives</figcaption>
      </td>
    </tr>
  </table>
</div>
<br>

<h3>
  Compare rendering times on a few scenes with moderately complex geometries with and without BVH acceleration. Present your results in a one-paragraph analysis.
</h3>
<p>
    Before implementing BVH, maxplanck took 55.4 seconds to render and CBlucy look 213.6 seconds on my laptop. After implementing BVH, the rendering time is greatly reduced.
    Planck now takes 0.0534 second and Lucy takes 0.0426 second. 
</p>
<br>

<h2 align="middle">Part 3: Direct Illumination (20 Points)</h2>
<!-- Walk through both implementations of the direct lighting function.
Show some images rendered with both implementations of the direct lighting function.
Focus on one particular scene with at least one area light and compare the noise levels in soft shadows when rendering with 1, 4, 16, and 64 light rays (the -l flag) and with 1 sample per pixel (the -s flag) using light sampling, not uniform hemisphere sampling.
Compare the results between uniform hemisphere sampling and lighting sampling in a one-paragraph analysis. -->

<h3>
  Walk through both implementations of the direct lighting function.
</h3>
<p>
    There are 2 methods, uniform hemisphere sampling and light sampling. 
</p>
<p>
  Uniform hemisphere sampling is implemented by first calculating the pdf.
  Next, the vector for n samples on the hemisphere were obtained and converted into world coordinates.
  A ray was created in this direction, and the hit point is set as its origin. Here, BVH from Part 2 was used to check for intersections.
  If an intersection is valid, the incoming radiance obtained was transformed into irradiance by multiplying it with the BSDF and a cosine term.
  The result was also divided by the pdf to get the Monte Carlo estimate. In this manner, 
  the result is gotten from summing and averaging all the samples on the hemisphere.
</p>
<p>
  Importance sampling / light sampling, as the name suggests, samples light sources in the scene.
  First, all lights in the scene is looped over.
  If the light is a point source, only one sample is taken because they're the same. Otherwise, many samples are obtained.
  Sampling returns information such as emitted radiance, pdf, the distance and direction vector from the hit point to the light.
  Vector w_in is obtained by converting incoming light direction from world to object space.
  If cos(w_in) > 0, a ray is generated upon vector w_in. If this ray is not blocked by other objects, it is taken into accumulations of light samples.
</p>
<h3>
  Show some images rendered with both implementations of the direct lighting function.
</h3>
<!-- Example of including multiple figures -->
<div align="middle">
  <table style="width:100%">
    <!-- Header -->
    <tr align="center">
      <th>
        <b>Uniform Hemisphere Sampling</b>
      </th>
      <th>
        <b>Light Sampling</b>
      </th>
    </tr>
    <br>
    <tr align="center">
      <td>
        <img src="images/3-a.png" align="middle" width="400px"/>
        <figcaption>CBbunny.dae</figcaption>
      </td>
      <td>
        <img src="images/3-1.png" align="middle" width="400px"/>
        <figcaption>CBbunny.dae</figcaption>
      </td>
    </tr>
    <br>
    <tr align="center">
      <td>
        <img src="images/3-b.png" align="middle" width="400px"/>
        <figcaption>CBspheres_lambertian.dae</figcaption>
      </td>
      <td>
        <img src="images/3-2.png" align="middle" width="400px"/>
        <figcaption>CBspheres_lambertian.dae</figcaption>
      </td>
    </tr>
    <br>
  </table>
</div>
<br>

<h3>
  Focus on one particular scene with at least one area light and compare the noise levels in <b>soft shadows</b> when rendering with 1, 4, 16, and 64 light rays (the -l flag) and with 1 sample per pixel (the -s flag) using light sampling, <b>not</b> uniform hemisphere sampling.
</h3>
<!-- Example of including multiple figures -->
<div align="middle">
  <table style="width:100%">
    <tr align="center">
      <td>
        <img src="images/r1.png" align="middle" width="200px"/>
        <figcaption>1 Light Ray (CBbunny.dae)</figcaption>
      </td>
      <td>
        <img src="images/r4.png" align="middle" width="200px"/>
        <figcaption>4 Light Rays (CBbunny.dae)</figcaption>
      </td>
    </tr>
    <tr align="center">
      <td>
        <img src="images/r16.png" align="middle" width="200px"/>
        <figcaption>16 Light Rays (CBbunny.dae)</figcaption>
      </td>
      <td>
        <img src="images/r64.png" align="middle" width="200px"/>
        <figcaption>64 Light Rays (CBbunny.dae)</figcaption>
      </td>
    </tr>
  </table>
</div>
<p>
    Soft shadow levels increase as light rays increase. This is because with a larger number of light rays, a more accurate estimation of irradiance is gotten through averaging.
</p>
<br>

<h3>
  Compare the results between uniform hemisphere sampling and lighting sampling in a one-paragraph analysis.
</h3>
<p>
    Light sampling yields a smoother result because it considers light going to the camera only instead of uniformly sampling radiance in all directions
    (some of which may be zero, which would yield a grainly result). 
</p>
<br>


<h2 align="middle">Part 4: Global Illumination (20 Points)</h2>
<!-- Walk through your implementation of the indirect lighting function.
Show some images rendered with global (direct and indirect) illumination. Use 1024 samples per pixel.
Pick one scene and compare rendered views first with only direct illumination, then only indirect illumination. Use 1024 samples per pixel. (You will have to edit PathTracer::at_least_one_bounce_radiance(...) in your code to generate these views.)
For CBbunny.dae, compare rendered views with max_ray_depth set to 0, 1, 2, 3, and 100 (the -m flag). Use 1024 samples per pixel.
Pick one scene and compare rendered views with various sample-per-pixel rates, including at least 1, 2, 4, 8, 16, 64, and 1024. Use 4 light rays.
You will probably want to use the instructional machines for the above renders in order to not burn up your own computer for hours. -->

<h3>
  Walk through your implementation of the indirect lighting function.
</h3>
<p>
    Indirect lighting function is implemented by recursion. Within each level of recursion, the following is accomplished:
    <br>
    1. Irradiance gathered from the previous level is obtained.
    <br>
    2. check if the max _ray_depth limit have been reached. If so, stop recursion.
    <br>
    3. Russian roulette is used to determine if ray-tracing should continue. This is probabilistically based (cpdf = 0.7). If not, recursion stops.
    <br>
    4. A ray is traced from hit point and whether it intersects some object is determined. If so, start next level of recursion.
    <br>
    The irradiances from all levels of recursion are summed together except the 1st level (direct illumination) to get indirect lighting.
</p>
<br>

<h3>
  Show some images rendered with global (direct and indirect) illumination. Use 1024 samples per pixel.
</h3>
<!-- Example of including multiple figures -->
<div align="middle">
  <table style="width:100%">
    <tr align="center">
      <td>
        <img src="images/4-1.png" align="middle" width="400px"/>
        <figcaption>CBspheres_lambertian.dae</figcaption>
      </td>
      <td>
        <img src="images/4-2.png" align="middle" width="400px"/>
        <figcaption>CBbunny.dae</figcaption>
      </td>
    </tr>
  </table>
</div>
<br>

<h3>
  Pick one scene and compare rendered views first with only direct illumination, then only indirect illumination. Use 1024 samples per pixel. (You will have to edit PathTracer::at_least_one_bounce_radiance(...) in your code to generate these views.)
</h3>
<!-- Example of including multiple figures -->
<div align="middle">
  <table style="width:100%">
    <tr align="center">
      <td>
        <img src="images/4a.png" align="middle" width="400px"/>
        <figcaption>Only direct illumination (example1.dae)</figcaption>
      </td>
      <td>
        <img src="images/4b.png" align="middle" width="400px"/>
        <figcaption>Only indirect illumination (example1.dae)</figcaption>
      </td>
    </tr>
  </table>
</div>
<br>
<p>
    Indirect illumination does not include the first bounce of light, which is why the illumination seems much more uniform and global. It also adds a level of realistic ambience to the picture.
</p>
<br>

<h3>
  For CBbunny.dae, compare rendered views with max_ray_depth set to 0, 1, 2, 3, and 100 (the -m flag). Use 1024 samples per pixel.
</h3>
<!-- Example of including multiple figures -->
<div align="middle">
  <table style="width:100%">
    <tr align="center">
      <td>
        <img src="images/m0.png" align="middle" width="400px"/>
        <figcaption>max_ray_depth = 0 (CBbunny.dae)</figcaption>
      </td>
      <td>
        <img src="images/m1.png" align="middle" width="400px"/>
        <figcaption>max_ray_depth = 1 (CBbunny.dae)</figcaption>
      </td>
    </tr>
    <tr align="center">
      <td>
        <img src="images/m2.png" align="middle" width="400px"/>
        <figcaption>max_ray_depth = 2 (CBbunny.dae)</figcaption>
      </td>
      <td>
        <img src="images/m3.png" align="middle" width="400px"/>
        <figcaption>max_ray_depth = 3 (CBbunny.dae)</figcaption>
      </td>
    </tr>
    <tr align="center">
      <td>
        <img src="images/m10.png" align="middle" width="400px"/>
        <figcaption>max_ray_depth = 100 (CBbunny.dae)</figcaption>
      </td>
    </tr>
  </table>
</div>
<br>
<p>
    Increasing ray depth increases the overall lighting of the scene. The difference is most drastic between 1 and 2 when global illumination is "turned on".
    The difference from 2 to 100 is barely noticeable, so there is really no need to set it high.
</p>
<br>

<h3>
  Pick one scene and compare rendered views with various sample-per-pixel rates, including at least 1, 2, 4, 8, 16, 64, and 1024. Use 4 light rays.
</h3>
<!-- Example of including multiple figures -->
<div align="middle">
  <table style="width:100%">
    <tr align="center">
      <td>
        <img src="images/s1.png" align="middle" width="400px"/>
        <figcaption>1 sample per pixel (CBspheres_lambertian.dae)</figcaption>
      </td>
      <td>
        <img src="images/s2.png" align="middle" width="400px"/>
        <figcaption>2 samples per pixel (CBspheres_lambertian.dae)</figcaption>
      </td>
    </tr>
    <tr align="center">
      <td>
        <img src="images/s4.png" align="middle" width="400px"/>
        <figcaption>4 samples per pixel (CBspheres_lambertian.dae)</figcaption>
      </td>
      <td>
        <img src="images/s8.png" align="middle" width="400px"/>
        <figcaption>8 samples per pixel (CBspheres_lambertian.dae)</figcaption>
      </td>
    </tr>
    <tr align="center">
      <td>
        <img src="images/s16.png" align="middle" width="400px"/>
        <figcaption>16 samples per pixel (CBspheres_lambertian.dae)</figcaption>
      </td>
      <td>
        <img src="images/s64.png" align="middle" width="400px"/>
        <figcaption>64 samples per pixel (CBspheres_lambertian.dae)</figcaption>
      </td>
    </tr>
    <tr align="center">
      <td>
        <img src="images/s1024.png" align="middle" width="400px"/>
        <figcaption>1024 samples per pixel (CBspheres_lambertian.dae)</figcaption>
      </td>
    </tr>
  </table>
</div>
<br>
<p>
    Increasing the sample rate reduces the graininess / noise level of the image. The effect is more obvious early on and less drastic later. 
    At 64 samples per pixel, the sample rate has to be drastically increased to 1024 to have a marginal (but noticeable) improvement.
</p>
<br>


<h2 align="middle">Part 5: Adaptive Sampling (20 Points)</h2>
<!-- Explain adaptive sampling. Walk through your implementation of the adaptive sampling.
Pick one scene and render it with at least 2048 samples per pixel. Show a good sampling rate image with clearly visible differences in sampling rate over various regions and pixels. Include both your sample rate image, which shows your how your adaptive sampling changes depending on which part of the image you are rendering, and your noise-free rendered result. Use 1 sample per light and at least 5 for max ray depth. -->

<h3>
  Explain adaptive sampling. Walk through your implementation of the adaptive sampling.
</h3>
<p>
    Adaptive sampling improves rendering time by reducing the number of samples taken of pixels that converges quickly. 
    Theoretically, illuminance within the pixel is normally distributed, which is why Z-test can be used to determine when to stop sampling (when confidence reaches 95%).
</p>
<img src="images/eq3.png" align="middle" width="400px"/>
<p>
    This formula is used, where 1.96 corresponds to 95% confidence. I is μ * maxTolerance. μ is the average, and default max tolerance is 0.05.
</p>
<br>

<h3>
  Pick two scenes and render them with at least 2048 samples per pixel. Show a good sampling rate image with clearly visible differences in sampling rate over various regions and pixels. Include both your sample rate image, which shows your how your adaptive sampling changes depending on which part of the image you are rendering, and your noise-free rendered result. Use 1 sample per light and at least 5 for max ray depth.
</h3>
<!-- Example of including multiple figures -->
<div align="middle">
  <table style="width:100%">
    <tr align="center">
      <td>
        <img src="images/5-1.png" align="middle" width="400px"/>
        <figcaption>Rendered image (CBbunny.dae)</figcaption>
      </td>
      <td>
        <img src="images/5a.png" align="middle" width="400px"/>
        <figcaption>Sample rate image (CBbunny.dae)</figcaption>
      </td>
    </tr>
    <tr align="center">
      <td>
        <img src="images/5-2.png" align="middle" width="400px"/>
        <figcaption>Rendered image (CBspheres_lambertian.dae)</figcaption>
      </td>
      <td>
        <img src="images/5b.png" align="middle" width="400px"/>
        <figcaption>Sample rate image (CBspheres_lambertian.dae)</figcaption>
      </td>
    </tr>
  </table>
</div>
<br>


</body>
</html>
